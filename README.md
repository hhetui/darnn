# 实验介绍
ver2        基础LSTM
ver2_1      改变隐向量长度

ver3        EN-DN结构

ver4        单独测试师兄给的CNN-selfattention结构

ver5        基础 DARNN 模型（回归）
ver5_1      改变隐向量长度

ver6        DARNN+self-attention结构
ver6_1      改变隐向量长度
ver6_2      改变隐向量长度
ver6_3      改变time_step

ver7        在DARNN+selfattention的ENDN中先用self-attention处理数据
ver8        将DARNN+selfattention的attention部分直接替换为self-attention
ver9        将DARNN+selfattention的attention部分直接替换为师兄给的CNNself-attention